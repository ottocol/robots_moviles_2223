# Pr√°ctica evaluable 1: moverse evitando obst√°culos

## Objetivo

**Desarrollad un programa en ROS que haga que el robot se mueva por el entorno evitando los obst√°culos**.  No tiene por qu√© tener un destino determinado, simplemente "vagabundear" por el entorno. Aunque en la asignatura veremos algoritmos de evitaci√≥n de obst√°culos bastante sofisticados, no se pide nada de eso ya que el objetivo es simplemente que record√©is la forma de trabajar con ROS.

Como idea sencilla pod√©is mirar las lecturas que apuntan m√°s o menos a la derecha y las que apuntan m√°s o menos a la izquierda (en lugar de tomar una sola pod√©is coger la media de varias que est√©n en un √°ngulo similar). Si las lecturas de la izquierda son menores que las de la derecha hay que girar hacia la derecha, y viceversa. Pod√©is a√±adir mejoras, como por ejemplo:

 - Que la velocidad de giro sea mayor si la diferencia entre izquierda y derecha es mayor.
 - Que la velocidad lineal sea proporcional a la distancia al obst√°culo m√°s cercano.
 - ... Cualquier otra idea que se os ocurra.
 
 > **IMPORTANTE** la idea es si es posible, probar el c√≥digo con los Turtlebot 2 del laboratorio, por lo que ser√≠a interesante que la prob√°rais antes en un simulador que use un sensor de rango similar a los Turtlebot 2 del laboratorio. El simulador *stage* con el mundo de ejemplo y la configuraci√≥n que os dejamps en moodle ser√≠a el m√°s parecido en este sentido (consultad el apartado "Probando un robot en el simulador Stage" de los apuntes de "[Introducci√≥n a ROS como usuario"](intro_ROS_usuario.html). Aunque parezca contraintuitivo, el simulador de Turtlebot 2 con la configuraci√≥n por defecto usa un sensor de rango muy distinto al laser de los robots reales y no es muy apropiado para este caso.

 > Cuidado, el nombre de los topics para los motores y el l√°ser cambian entre Stage y el  Turtlebot real
 
> |         | Turtlebot real                   | Stage        |
|---------|----------------------------------|--------------|
| L√°ser   | `/scan`                          | `/base_scan` |
| Motores | `/mobile_base/commands/velocity` | `/cmd_vel`   |


## Ayuda para la implementaci√≥n: sensores de rango 2D en ROS

Los sensores de rango 2D dan distancias a obst√°culos en un rango angular determinado, normalmente los sensores apuntan hacia donde est√° mirando el robot. Pod√©is obtener la informaci√≥n del sensor normalmente en el topic `/scan` o `/base_scan`, dependiendo del robot o del simulador usado. Probad a ver cu√°l aparece al hacer un `rostopic list`.

Los mensajes en este *topic* son del tipo `sensor_msgs/LaserScan`. El campo m√°s importante de estos mensajes es el array `ranges`, pero adem√°s hay otros campos importantes. Pod√©is consultarlos por ejemplo en [http://docs.ros.org/kinetic/api/sensor_msgs/html/msg/LaserScan.html](http://docs.ros.org/kinetic/api/sensor_msgs/html/msg/LaserScan.html). 

Dos campos interesantes son `angle_min` y `angle_max`, que como indica la p√°gina anterior son el √°ngulo donde empieza el scan y donde acaba. Teniendo en cuenta adem√°s el campo `angle_increment` podemos saber en qu√© √°ngulo apunta cada lectura del array ranges. La [0] apuntar√° a `angle_min`, la [1] a `angle_min+angle_increment`, y as√≠ sucesivamente.

Llevad cuidado porque en ROS el sentido de giro positivo es "a izquierdas" y eso da lugar a algunas consecuencias un poco antiintuitivas.

Al menos en los sensores simulados en Stage y en Gazebo con el Turtlebot 2, las primeras posiciones del array apuntan "a la derecha" del robot visto desde su punto de vista (√°ngulos negativos), y las √∫ltimas "a la izquierda" (√°ngulos positivos). El punto medio del array ser√≠an 0 radianes, la direcci√≥n en la que mira el robot. Por ejemplo en el scan del Turtlebot en gazebo va de -0,52 radianes aprox. a 0.52.

Esto es as√≠ para ser coherente con el sistema de coordenadas de ROS: a mayor √°ngulo "m√°s giras a la izquierda" (en [https://answers.ros.org/question/198843/need-explanation-on-sensor_msgslaserscanmsg/](https://answers.ros.org/question/198843/need-explanation-on-sensor_msgslaserscanmsg/) ten√©is una figura que lo explica mejor). 

En conclusi√≥n: para saber el √°ngulo de una lectura ten√©is que hacer cuentas con `angle_min`, `angle_max` y `angle_increment`. 

En los Turtlebot 3 simulados en Gazebo las lecturas empiezan con angle_min=0 (al frente del robot) y terminan en 6.28 radianes (dan una visi√≥n de 360 grados alrededor del robot).

## Prueba del c√≥digo en el Turtlebot real

El d√≠a 28 pod√©is probar el c√≥digo en los robots. Cosas importantes:

- Como solo hay un Turtlebot por mesa, lo m√°s sencillo es que os junt√©is varios grupos para probar el c√≥digo. No es necesario que prob√©is el c√≥digo de todos, pero si pod√©is, mejor
- El turtlebot real tiene un l√°ser con un campo de visi√≥n de 240 grados aprox.,  pr√°cticamente igual que el que simul√°bamos en stage,
- El topic del laser es `/scan`, el de los motores es `/mobile_base/commands/velocity
- Los robots tienen ROS Indigo/Kinetic, que usa **Python 2**:
    * si ten√©is alg√∫n print, no debe llevar par√©ntesis
    * si hay alguna √± o acento en los comentarios, dar√° error, poned la siguiente l√≠nea al principio del archivo: # -*- coding: utf-8 -*-
- **Importante**: el laser est√° montado "boca abajo", por lo que el array "ranges" est√° al rev√©s de como lo esper√°is üò¨. Para que funcione vuestro algoritmo creo que lo m√°s sencillo es "invertir" el array lo primero de todo en el callback del l√°ser, pero pod√©is hacerlo como quer√°is
```python
//callback del laser
def callback(msg):  
   msg.ranges = list(msg.ranges)
   msg.ranges.reverse()
   //a partir de aqu√≠ ya todo ser√≠a igual que en vuestro algoritmo...
   //...
```   

> CUIDADO: Copiad al robot solo el archivo .py con vuestra pr√°ctica 1. No es necesario el workspace entero (catkin_ws). **NO COPIEIS EL CATKIN_WS al robot ya que ya tiene uno, necesario para su funcionamiento y lo machacar√≠ais**

En el robot poned en marcha solo los motores y el laser, la c√°mara no es necesaria. Recordad que las instrucciones completas est√°n en la gu√≠a de laboratorio de los turtlebots.

Pod√©is documentar este apartado con 1-2 p√°ginas m√°ximo explicando:

- Qu√© ha funcionado y qu√© no
- Semejanzas y diferencias (si las hay) entre el comportamiento del robot en el entorno simulado y en el real
- Si hab√©is modificado alg√∫n par√°metro del algoritmo o el c√≥digo, incluid el c√≥digo modificado explicando el por qu√© lo hab√©is cambiado (salvo el tema del `reverse` en el array, que ten√©is que hacer todos igualmente)
- Adjuntad videos del comportamiento del robot para ilustrar gr√°ficamente vuestras explicaciones


## Normas de entrega

La pr√°ctica se puede desarrollar **individualmente o bien por parejas**. 

> Pod√©is compartir con vuestros compa√±eros las ideas de c√≥mo funciona el algoritmo (y de hecho si lo discut√≠s y os dais ideas entre vosotros ser√° m√°s enriquecedor) pero el c√≥digo Python o C++ deber√≠a ser exclusivamente vuestro. Ser√≠a recomendable que si hab√©is colaborado en el desarrollo del algoritmo os referenci√©is unos a otros en la documentaci√≥n entregada ("la idea del algoritmo ha surgido en colaboraci√≥n con XXX e YYY..."). As√≠ evitar√©is que en caso de darme cuenta de la semejanza asuma que os hab√©is copiado.

La pr√°ctica se entregar√° a trav√©s de moodle. El plazo de entrega concluye el **martes 4 de octubre a las 23:59**. Si la hac√©is por parejas solo deb√©is hacer una entrega conjunta desde el moodle de uno de los dos componentes. En la documentaci√≥n figurar√° el nombre de ambas personas.

Ten√©is que entregar:

- **C√≥digo fuente** del programa con comentarios de c√≥mo funciona
- **Documentaci√≥n de las pruebas realizadas**: en qu√© circunstancias funciona el algoritmo, en cu√°les ha fallado, por qu√© cre√©is que lo ha hecho y c√≥mo cre√©is que se podr√≠a solucionar. Pod√©is incluir capturas de pantalla, adjuntar videos, los ficheros de los mundos...
    + Como m√≠nimo probad un mundo en el simulador stage (usando el `ejemplo.world` que vimos en la introducci√≥n a ROS), y otro en el simulador gazebo. Ten en cuenta que el sensor simulado en stage (un l√°ser) tiene mucho m√°s campo de visi√≥n que el de Gazebo (una c√°mara 3D): 270 grados para el l√°ser vs. 60 para la c√°mara, y eso influir√° en el comportamiento del algoritmo, m√°s que el que sea un entorno 2D o 3D.
  
**IMPORTANTE**: en evitaci√≥n de obst√°culos (como en todo lo dem√°s) **no hay algoritmos perfectos  ni que funcionen siempre** igual de bien en todos los casos. No deb√©is intentar "esconder" los casos en los que vuestro c√≥digo no funciona, sino documentarlos, intentar encontrarle una explicaci√≥n y (idealmente) implementar mejoras que lo solucionen, o al menos proponerlas. Para poder aplicar un algoritmo es importante conocer sus limitaciones.

## Baremo de evaluaci√≥n

- **Hasta un 6**: c√≥digo entregado y documentado (con comentarios al fuente) y una explicaci√≥n breve (de 1/2 a 1 p√°gina) de la idea b√°sica de vuestro algoritmo
- **Hasta 1 punto m√°s**: todo lo anterior m√°s pruebas documentadas en al menos dos entornos simulados que sean distintos (p.ej. pocos obst√°culos vs muchos). Pod√©is buscar entornos por internet o crearlos vosotros.
- **Hasta 1.5 puntos m√°s**: todo lo anterior m√°s hacer que el robot en lugar de "vagabundear" sin rumbo intente ir a un destino que se especificar√° como una coordenada `(x,y)` en el sistema de coordenadas `odom`. El programa deber√≠a admitir como argumentos estas coordenadas.
- **Hasta 1.5 puntos m√°s** por probar el c√≥digo en el robot real y documentar las pruebas seg√∫n se indica en el apartado correspondiente.